{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application to detect potholes \n",
    "\n",
    "This notebook works through 3 classifications of common objects on the road: stoplights, cars, and potholes. The Tesla 2020.12* software already includes cars, cones, stoplights/signs, humans, bikes, and road markings, but not potholes. \n",
    "YOLOV3 model info. A list of the models can be found here https://pytorch.org/docs/stable/torchvision/models.html_.\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "1. Extract frames from video footage\n",
    "2. Define object classes within the images \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames from video: \n",
    "\n",
    "- run extract_frame_video.py on each of the files\n",
    "- TeslaCam records at 36 fps. I only utilize every 1 in 10 frames. \n",
    "\n",
    "### Define object classes and setup config files: \n",
    "\n",
    "- run the Python GUI in the director for each class\n",
    "- draw boxes around the object and a file with coordinates is automatically written out with bbox.py\n",
    "- create the train.txt and val.txt files with database_files.py. These contain the images for each set.\n",
    "- get the YOLOv3 weights file with: wget https://pjreddie.com/media/files/yolov3.weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "from utils.parse_config import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "#import torch.optim as optim\n",
    "import torch.optim as opt\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--epochs EPOCHS]\n",
      "                             [--image_folder IMAGE_FOLDER]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--model_config_path MODEL_CONFIG_PATH]\n",
      "                             [--data_config_path DATA_CONFIG_PATH]\n",
      "                             [--weights_path WEIGHTS_PATH]\n",
      "                             [--class_path CLASS_PATH]\n",
      "                             [--conf_thres CONF_THRES] [--nms_thres NMS_THRES]\n",
      "                             [--n_cpu N_CPU] [--img_size IMG_SIZE]\n",
      "                             [--checkpoint_interval CHECKPOINT_INTERVAL]\n",
      "                             [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                             [--use_cuda USE_CUDA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/jennifercooper/Library/Jupyter/runtime/kernel-0672d384-4cb4-46d1-80bc-6d42a17cd7aa.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--epochs\", type=int, default=20, help=\"number of epochs\")\n",
    "parser.add_argument(\"--image_folder\", type=str, default=\"data/artifacts/images\", help=\"path to dataset\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"size of each image batch\")\n",
    "parser.add_argument(\"--model_config_path\", type=str, default=\"config/yolov3.cfg\", help=\"path to model config file\")\n",
    "parser.add_argument(\"--data_config_path\", type=str, default=\"config/coco.data\", help=\"path to data config file\")\n",
    "parser.add_argument(\"--weights_path\", type=str, default=\"config/yolov3.weights\", help=\"path to weights file\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"config/coco.names\", help=\"path to class label file\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.8, help=\"object confidence threshold\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"iou thresshold for non-maximum suppression\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=0, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--checkpoint_interval\", type=int, default=1, help=\"interval between saving model weights\")\n",
    "parser.add_argument(\"--checkpoint_dir\", type=str, default=\"checkpoints\", help=\"directory where model checkpoints are saved\")\n",
    "parser.add_argument(\"--use_cuda\", type=bool, default=True, help=\"whether to use cuda if available\")\n",
    "opt = parser.parse_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 20\n",
    "batch_size = 16\n",
    "conf_thres = 0.8 #object confidence threshold\n",
    "nms_thres  = 0.4 #iou thresshold for non-maximum suppression\n",
    "img_size   = 416\n",
    "\n",
    "checkpoint_interval = 1 #interval between saving model weights\n",
    "checkpoint_dir      = 'data/checkpoint'\n",
    "\n",
    "#paths to important files \n",
    "image_folder      = '/Users/jennifercooper/Projects/Tesla/PyTorchTraining/Potholes/data/artifacts/images'\n",
    "model_config_path = '/Users/jennifercooper/Projects/Tesla/PyTorchTraining/Potholes/data/config/yolov3.cfg'\n",
    "weights_path      = '/Users/jennifercooper/Projects/Tesla/PyTorchTraining/Potholes/data/config/yolov3.weights'\n",
    "class_path        = '/Users/jennifercooper/Projects/Tesla/PyTorchTraining/Potholes/data/config/tesla_dashcam.names'\n",
    "data_config_path  = '/Users/jennifercooper/Projects/Tesla/PyTorchTraining/Potholes/data/config/tesla_dashcam.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'data_config_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8a52c732be89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get data configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'data_config_path'"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "#classes = load_classes(opt.class_path)\n",
    "classes = load_classes(class_path)\n",
    "\n",
    "# Get data configuration\n",
    "data_config = parse_data_config(opt.data_config_path)\n",
    "train_path = data_config[\"train\"]\n",
    "\n",
    "# Get hyper parameters\n",
    "hyperparams = parse_model_config(opt.model_config_path)[0]\n",
    "learning_rate = float(hyperparams[\"learning_rate\"])\n",
    "momentum = float(hyperparams[\"momentum\"])\n",
    "decay = float(hyperparams[\"decay\"])\n",
    "burn_in = int(hyperparams[\"burn_in\"])\n",
    "\n",
    "# Initiate model\n",
    "model = Darknet(opt.model_config_path)\n",
    "model.load_weights(opt.weights_path)\n",
    "#model.apply(weights_init_normal)\n",
    "\n",
    "#if cuda:\n",
    "#    model = model.cuda()\n",
    "model.to('cpu')\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
